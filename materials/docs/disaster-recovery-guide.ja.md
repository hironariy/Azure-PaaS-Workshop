# BCDR ガイド（Azure PaaS ワークショップ ブログアプリケーション）

このガイドでは、本ワークショップの PaaS アーキテクチャに対する、実践的な **事業継続（Business Continuity）/ 災害復旧（Disaster Recovery）= BCDR** の進め方を説明します。

- **Frontend**: Azure Static Web Apps（SWA）
- **Backend**: Azure App Service（Linux, Node.js）
- **Database**: Azure Cosmos DB for MongoDB vCore
- **Secrets**: Azure Key Vault
- **Observability**: Application Insights + Log Analytics

> 対象範囲: 現行 Bicep テンプレートは **単一リージョンのプライマリ環境** をデプロイします。本ガイドでは、この前提に対してワークショップで実施しやすい継続性・DR ランブックを示します。

---

## 1. 継続性目標（RPO / RTO）を定義する

まず次を明確化します。

- **RPO（Recovery Point Objective）**: 許容できるデータ損失幅
- **RTO（Recovery Time Objective）**: 許容できるサービス停止時間

ワークショップ向けの目安:

- RPO: 1〜24 時間（バックアップ頻度に依存）
- RTO: 1〜4 時間（自動化レベルに依存）

---

## 2. このアーキテクチャで想定する障害シナリオ

### 2.1 コンポーネント単位の障害（最も一般的）

- App Service インスタンスの異常
- Cosmos DB 接続の一時的障害
- Key Vault アクセス権（RBAC）設定ミス
- デプロイ後のアプリケーション不具合

主な対策:

- App Service ヘルスチェック（`/health`, `/api/health`）
- バックエンド/フロントエンドの迅速な再デプロイ
- 既知の正常ビルドへのロールバック

### 2.2 リージョン障害（低頻度・高影響）

- プライマリリージョンの停止または深刻な劣化

主な対策:

- セカンダリリージョン用リソースグループを事前定義
- Bicep による環境再構築
- DNS/トラフィック切替ランブック

---

## 3. サービス別 BCDR 方針

## 3.1 Static Web Apps（フロントエンド）

復旧原則:

- フロントエンドはステートレスで、ソースから再構築可能

BCDR 対応:

1. ソースコードと CI ワークフローを GitHub（等）で管理する。
2. 環境変数/アプリ設定をコード化または手順書化する。
3. DR 時はセカンダリリージョンに SWA を展開し、ユーザートラフィックを切り替える。

## 3.2 App Service（バックエンド）

復旧原則:

- バックエンド実行環境は、ソース/成果物 + 設定で再現できる

BCDR 対応:

1. バックエンド成果物を再生成可能に保つ（`npm ci`、build、deploy パッケージ/コンテナ）。
2. シークレットは Key Vault に格納する（現行実装どおり Key Vault reference を利用）。
3. 切替前に `/health` と `/api/health` で準備完了を確認する。

## 3.3 Cosmos DB for MongoDB vCore（データ）

復旧原則:

- データ層が RPO を左右するため、最優先の復旧依存として扱う

BCDR 対応（ワークショップ向け）:

1. 論理バックアップ（`mongodump`）と復元検証（`mongorestore`）を定期実施する。
2. バックアップ保持期間を RPO に合わせる。
3. 本番要件に応じて、HA やジオ戦略など上位の可用性機能を検討する。

> 利用ティアで使用可能な機能と復元オプションは、Cosmos DB for MongoDB vCore の最新 Microsoft ドキュメントで必ず確認してください。

## 3.4 Key Vault（シークレット）

復旧原則:

- シークレット/設定は再現可能かつ復旧可能であること

BCDR 対応:

1. シークレット登録/更新手順をスクリプトまたはランブック化する。
2. 重要な初期シークレットの安全なエスカレーション/保管手順を定義する。
3. フェールオーバー時にセカンダリリージョンへシークレットを再投入する。

---

## 4. ワークショップ推奨 DR ランブック

### フェーズ A: 事前準備（通常時）

1. プライマリ/セカンダリ用の Bicep パラメータファイルを管理する。
2. バックエンド/フロントエンドのデプロイパイプラインを定期検証する。
3. データバックアップと復元演習を定期実施する。
4. 運用チェックリスト（担当者、コマンド、検証手順）を維持する。

### フェーズ B: インシデント宣言

1. 影響範囲を確認する（コンポーネント障害かリージョン障害か）。
2. 不要なデプロイを停止する。
3. DR モードを宣言し、インシデント指揮者と連絡責任者を明確化する。

### フェーズ C: 復旧実行

1. セカンダリリージョンのリソースを Bicep で展開/確認する。
2. 最新の有効バックアップから DB を復元する（または待機系を活用）。
3. バックエンドをデプロイし、ヘルスエンドポイントを確認する。
4. フロントエンドをデプロイし、ログインと API 通信を確認する。
5. DNS/エントリポイントをセカンダリ環境へ切り替える。

### フェーズ D: フェールオーバー後検証

1. 主要ユーザーフローを確認:
   - 投稿一覧の閲覧
   - サインイン
   - 投稿作成/編集
2. Application Insights / Log Analytics のテレメトリを確認する。
3. 実測 RTO/RPO を記録し、改善項目を洗い出す。

---

## 5. 復旧検証チェックリスト

- セカンダリリージョンで Bicep デプロイが成功する
- バックエンドのヘルスエンドポイントが期待どおり応答する
- DB 接続と CRUD 操作が成功する
- Entra ID 認証フローが切替後も機能する
- 監視とアラートが DR 環境でも継続する
- 目標 RTO 以内でランブックを完了できる

---

## 6. 四半期ごとの最小 DR 演習

四半期に最低 1 回、次を実施します。

1. プライマリ停止を想定したシミュレーション
2. Bicep からセカンダリ環境を展開
3. 最新バックアップからデータ復元
4. トラフィック切替とスモークテスト
5. 学びを記録し、ランブックを更新

---

## 7. 今後の拡張（任意）

- Azure DevOps / GitHub Actions によるフェールオーバー手順自動化
- マルチリージョン active-passive 構成への拡張
- バックアップ自動化と整合性検証の強化
- RTO/RPO SLO に連動したサービスアラートの実装
